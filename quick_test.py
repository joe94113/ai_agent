# quick_test.py
import io
import json
import os
import re
from contextlib import redirect_stdout
from unittest.mock import patch
from typing import Any, Dict, List, Tuple, Optional
from typing import Union

import onboarding_fsm as agent  # â† æ”¹æˆä½ çš„æª”åï¼ˆä¸è¦åŠ  .pyï¼‰


# -----------------------------
# ç°¡æ˜“ä¸­æ–‡å­—æ•¸å­—è½‰ intï¼ˆå¤ æ¸¬è©¦ç”¨ï¼‰
# -----------------------------
CN_MAP = {
    "é›¶": 0, "ä¸€": 1, "äºŒ": 2, "å…©": 2, "ä¸‰": 3, "å››": 4, "äº”": 5,
    "å…­": 6, "ä¸ƒ": 7, "å…«": 8, "ä¹": 9
}

def cn_to_int(s: str) -> int:
    s = s.strip()
    if not s:
        return 0
    if s.isdigit():
        return int(s)

    # åã€åä¸€ã€äºŒåã€äºŒåä¸‰
    if s == "å":
        return 10
    if "å" in s:
        left, right = s.split("å", 1)
        tens = CN_MAP.get(left, 1) if left else 1
        ones = CN_MAP.get(right, 0) if right else 0
        return tens * 10 + ones

    return CN_MAP.get(s, 0)


# -----------------------------
# è§£ææ¡Œå‹ï¼šå››äººæ¡Œäº”å€‹ / 4äººæ¡Œ5å¼µ / 8äººæ¡Œ1å€‹
# -----------------------------
RES_PAIR_RE = re.compile(
    r"([0-9ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)\s*äºº?\s*æ¡Œ?\s*([0-9ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)\s*(?:å¼µ|å€‹|æ¡Œ|ä½)?"
)

def parse_resources(text: str) -> List[Dict[str, int]]:
    out: List[Dict[str, int]] = []
    for m in RES_PAIR_RE.finditer(text):
        ps = cn_to_int(m.group(1))
        st = cn_to_int(m.group(2))
        if ps > 0 and st >= 0:
            out.append({"party_size": ps, "spots_total": st})

    # åˆä½µåŒ party_size
    merged: Dict[int, int] = {}
    for r in out:
        merged.setdefault(r["party_size"], 0)
        merged[r["party_size"]] += r["spots_total"]

    return [{"party_size": ps, "spots_total": merged[ps]} for ps in sorted(merged.keys())]


# -----------------------------
# è§£ææ™‚é–“ï¼š08:00-17:00 / 8é»åˆ°17é» / æ—©å…«æ™šäº”
# -----------------------------
TIME_RANGE_RE1 = re.compile(r"(\d{1,2})[:ï¼š](\d{2})\s*(?:-|â€“|~|åˆ°|è‡³)\s*(\d{1,2})[:ï¼š](\d{2})")
TIME_RANGE_RE2 = re.compile(r"(\d{1,2})\s*(?:é»|æ™‚)\s*(?:-|â€“|~|åˆ°|è‡³)\s*(\d{1,2})\s*(?:é»|æ™‚)")
TIME_RANGE_RE3 = re.compile(r"æ—©([0-9ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+).*(?:æ™š|åˆ°æ™šä¸Š)([0-9ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)")

def to_hhmm(h: int, m: int) -> str:
    h = max(0, min(23, int(h)))
    m = max(0, min(59, int(m)))
    return f"{h:02d}{m:02d}"

def extract_time_range(text: str) -> Optional[Tuple[str, str]]:
    t = text.strip()

    m = TIME_RANGE_RE1.search(t)
    if m:
        sh, sm, eh, em = int(m.group(1)), int(m.group(2)), int(m.group(3)), int(m.group(4))
        return to_hhmm(sh, sm), to_hhmm(eh, em)

    m = TIME_RANGE_RE2.search(t)
    if m:
        sh, eh = int(m.group(1)), int(m.group(2))
        return to_hhmm(sh, 0), to_hhmm(eh, 0)

    m = TIME_RANGE_RE3.search(t)
    if m:
        sh = cn_to_int(m.group(1))
        eh = cn_to_int(m.group(2))
        return to_hhmm(sh, 0), to_hhmm(eh, 0)

    return None


def parse_business_hours_json(text: str) -> List[Dict[str, Any]]:
    rng = extract_time_range(text)
    if not rng:
        return []
    start, end = rng

    # day: 0=é€±ä¸€ ... 6=é€±æ—¥
    if ("æ¯å¤©" in text) or ("æ¯æ—¥" in text):
        days = list(range(7))
    elif ("é€±ä¸€åˆ°é€±å…­" in text) or ("é€±ä¸€ï½é€±å…­" in text) or ("é€±ä¸€è‡³é€±å…­" in text):
        days = list(range(6))
    elif ("é€±ä¸€åˆ°é€±äº”" in text) or ("é€±ä¸€ï½é€±äº”" in text) or ("é€±ä¸€è‡³é€±äº”" in text):
        days = list(range(5))
    else:
        # æ¸¬è©¦ç”¨ fallbackï¼šæ²’èªªå°±ç•¶æ¯å¤©
        days = list(range(7))

    # å…¬ä¼‘
    if ("é€±æ—¥" in text or "æ˜ŸæœŸæ—¥" in text) and ("å…¬ä¼‘" in text or "ä¼‘" in text):
        days = [d for d in days if d != 6]

    out: List[Dict[str, Any]] = []
    for d in days:
        out.append({"open": {"day": d, "time": start}, "close": {"day": d, "time": end}})
    return out


# -----------------------------
# Mock æ‰ llm_extractï¼šé¿å…çœŸçš„æ‰“ Ollamaï¼ˆæ¸¬ FSM æµç¨‹æœ€å¿«ï¼‰
# -----------------------------
def fake_llm_extract(step_name: str, user_text: str, state: dict) -> dict:
    if step_name == "store_name":
        name = user_text.strip()
        return {"store_name": name} if name else {}

    if step_name == "resources":
        res = parse_resources(user_text)
        return {"resources": res} if res else {}

    if step_name == "business_hours_json":
        bh = parse_business_hours_json(user_text)
        return {"business_hours_json": bh} if bh else {}

    # Step 11 recommendation_patchï¼šè®“æ¼”ç®—æ³• fallback è‡ªå·±ç®—ï¼ˆæœ€å¿«ï¼‰
    if step_name == "recommendation_patch":
        return {}

    # å…¶ä»–æ­¥é©Ÿï¼šFSM å¤§å¤šç”¨è¦å‰‡è™•ç†ï¼Œé€™è£¡å› {} å³å¯
    return {}


# -----------------------------
# å¾ã€Œæ–°å°å‡ºçš„ stdout ç‰‡æ®µã€æŠ“å‡ºã€Œæœ€å¾Œä¸€æ®µ ğŸ¤– Agentï¼š...ã€
# -----------------------------
def extract_last_agent_block(delta: str) -> str:
    if not delta:
        return ""

    marker = "ğŸ¤– Agentï¼š"
    idx = delta.rfind(marker)
    if idx == -1:
        return delta.strip()

    block = delta[idx:].strip()
    return block

def auto_answer(question_block: str) -> str:
    q = (question_block or "").replace(" ", "")

    # âœ… 1) å…ˆè™•ç†ã€Œç¢ºèªé¡Œã€ï¼ˆä¸€å®šè¦æ”¾æœ€å‰é¢ï¼‰
    if "é€™æ¨£å°å—" in q and ("A." in q and "B." in q):
        return "A"

    # âœ… 2) å†è™•ç†ç‡Ÿæ¥­æ™‚é–“è¼¸å…¥é¡Œ
    if "ç‡Ÿæ¥­æ™‚é–“" in q:
        return "æ¯å¤© 08:00-17:00"

    if "ç·šä¸Šè¨‚ä½å»ºè­°" in q and "ç›´æ¥æ¡ç”¨" in q and "æˆ‘æƒ³èª¿æ•´" in q:
        return "A"  # å¤§éƒ¨åˆ† caseï¼šè®“æ¸¬è©¦èƒ½æ”¶æ–‚ã€è·‘å®Œ

    # âœ… Step11ï¼šä¿®æ”¹æç¤ºï¼ˆè¦å›ã€Œä¸€å¥èª¿æ•´å…§å®¹ã€ï¼Œä¸èƒ½å› A/Bï¼‰
    if "ä½ æƒ³æ€éº¼èª¿æ•´" in q:
        return "å¿™çš„æ™‚å€™æ¯ 30 åˆ†é˜æœ€å¤š 2 çµ„ç·šä¸Šè¨‚ä½"

    # åº—å
    if "åº—å" in q:
        return "è‡ªå‹•æ¸¬è©¦åº—"

    # æ¡Œå‹
    if ("æ¡Œå‹" in q) or ("å¹¾å¼µ" in q) or ("äººæ¡Œ" in q):
        return "4äººæ¡Œ2å¼µ 6äººæ¡Œ1å¼µ"

    # ç”¨é¤æ™‚é–“ A/B/C
    if "ç”¨é¤" in q and ("A." in q or "B." in q or "C." in q):
        return "B"

    # ä½µæ¡Œ
    if "ä½µèµ·ä¾†" in q and ("A." in q and "B." in q):
        return "A"

    # æœ€å¤§äººæ•¸
    if "æœ€å¤š" in q and ("å¹¾å€‹äºº" in q or "å¹¾äºº" in q):
        return "8äºº"

    # ç·šä¸Šè¨‚ä½è§’è‰²
    if "æ‰®æ¼”ä»€éº¼è§’è‰²" in q and ("A." in q or "B." in q or "C." in q):
        return "B"

    # æœ€å¿™æ™‚æ®µ
    if "æœ€å®¹æ˜“å¿™èµ·ä¾†" in q and ("A." in q or "B." in q or "C." in q or "D." in q):
        return "C"

    # å¿™æ™‚ç·šä¸Šä½”æ¯”
    if "ä½”å¤šå°‘ä½ç½®" in q and ("A." in q or "B." in q or "C." in q):
        return "B"

    # å¿™æ™‚ç­–ç•¥
    if "æ¯”è¼ƒå¸Œæœ›æ€éº¼åš" in q and ("A." in q or "B." in q or "C." in q):
        return "A"

    # no-show
    if "æ²’ä¾†" in q and ("A." in q or "B." in q or "C." in q):
        return "B"

    # Step11 æ¥å—/ä¿®æ”¹
    if "ç›´æ¥æ¡ç”¨" in q and "æˆ‘æƒ³èª¿æ•´" in q:
        return "A"

    # æœ€å¾Œä¿åº•ï¼šé¸é …é¡Œå°± A
    if "A." in q and "B." in q:
        return "A"

    return "A"

def classify_step(q: str) -> str:
    t = (q or "").replace(" ", "")

    if "è«‹å•åº—å" in t or "åº—åæ˜¯ä»€éº¼" in t:
        return "store_name"
    if "æ¡Œå‹" in t or "äººæ¡Œ" in t:
        return "resources"
    if "ç”¨é¤" in t and ("å¤šä¹…" in t or "å¤§ç´„" in t):
        return "duration"
    if "æ•´ç†ä¸€ä¸‹ç‡Ÿæ¥­æ™‚é–“" in t and "é€™æ¨£å°å—" in t:
        return "hours_confirm"
    if "ç‡Ÿæ¥­æ™‚é–“" in t:
        return "hours"
    if "ä½µèµ·ä¾†" in t:
        return "merge_tables"
    if "æœ€å¤š" in t and ("å¹¾å€‹äºº" in t or "ä¸€èµ·ç”¨é¤" in t):
        return "max_party_size"
    if "æ‰®æ¼”ä»€éº¼è§’è‰²" in t:
        return "online_role"
    if "æœ€å®¹æ˜“å¿™èµ·ä¾†" in t:
        return "peak_period"
    if "ä½”å¤šå°‘ä½ç½®" in t:
        return "peak_ratio"
    if "æ¯”è¼ƒå¸Œæœ›æ€éº¼åš" in t:
        return "peak_strategy"
    if "æ²’ä¾†" in t or "æ”¾é³¥" in t:
        return "no_show"

    # âœ… Step11 å…©ç¨®å•é¡Œ
    if "ç·šä¸Šè¨‚ä½å»ºè­°" in t and "ç›´æ¥æ¡ç”¨" in t and "æˆ‘æƒ³èª¿æ•´" in t:
        return "step11_confirm"
    if "ä½ æƒ³æ€éº¼èª¿æ•´" in t:
        return "step11_modify"

    return "unknown"

# -----------------------------
# è·‘ä¸€å€‹æ¸¬è©¦æ¡ˆä¾‹ï¼ˆè…³æœ¬åŒ– inputï¼‰+ ç”¢ç”Ÿ interleaved log
# -----------------------------
InputPlan = Union[List[str], Dict[str, List[str]]]

def run_case(
    name: str,
    inputs: InputPlan,
    use_real_llm: bool = False,
    log_dir: str = "test_logs",
    max_turns: int = 120,
    allow_autofill: bool = True,
):
    os.makedirs(log_dir, exist_ok=True)

    turns: List[Dict[str, Any]] = []
    buf = io.StringIO()
    last_len = 0
    input_calls = 0

    # âœ… æ¯å€‹ step è¢«å•åˆ°ç¬¬å¹¾æ¬¡ï¼ˆé‡å•æ™‚æœƒå–ä¸‹ä¸€å€‹ç­”æ¡ˆï¼‰
    step_counts: Dict[str, int] = {}

    # âœ… list æ¨¡å¼æ‰éœ€è¦ iterator
    it = iter(inputs) if isinstance(inputs, list) else None

    # âœ… è¨ˆæ•¸ï¼šæ˜¯å¦çœŸçš„æ‰“åˆ° Ollamaï¼ˆrequests.post è¢«å‘¼å«å¹¾æ¬¡ï¼‰
    llm_calls = {"n": 0}
    real_post = agent.requests.post

    def wrapped_post(url, *args, **kwargs):
        llm_calls["n"] += 1
        return real_post(url, *args, **kwargs)

    def pick_from_plan(step: str) -> Tuple[str, bool]:
        """
        å›å‚³ (answer, auto_used)
        - dict æ¨¡å¼ï¼šä¾ step å–ç­”æ¡ˆï¼›åŒ step é‡å•æœƒä¾åºå–ä¸‹ä¸€å€‹ï¼›ç”¨å®Œå°±æ²¿ç”¨æœ€å¾Œä¸€å€‹
        - list æ¨¡å¼ï¼šç…§é †åºå–ï¼›ç”¨å®Œæ‰ auto
        """
        auto_used = False

        # âœ… dict(step-plan) æ¨¡å¼ï¼šçœŸå¯¦ LLM å¼·çƒˆå»ºè­°ç”¨é€™å€‹
        if isinstance(inputs, dict):
            seq = inputs.get(step)
            if seq is None:
                seq = inputs.get("default", [])

            if isinstance(seq, list) and len(seq) > 0:
                k = step_counts.get(step, 0)
                step_counts[step] = k + 1
                ans = seq[k] if k < len(seq) else seq[-1]
                return str(ans), False

            # æ²’æä¾›å°± auto
            return "", True

        # âœ… list æ¨¡å¼
        assert it is not None
        try:
            ans = next(it)
            return str(ans), False
        except StopIteration:
            return "", True

    def scripted_input(prompt: str = "") -> str:
        nonlocal last_len, input_calls
        input_calls += 1
        if input_calls > max_turns:
            raise RuntimeError(f"[{name}] è¶…é max_turns={max_turns}ï¼Œç–‘ä¼¼ LLM ä¸€ç›´é‡å•/å¡ä½ã€‚")

        so_far = buf.getvalue()
        delta = so_far[last_len:]
        last_len = len(so_far)

        q = extract_last_agent_block(delta) or "ğŸ¤– Agentï¼š<æœªæ•æ‰åˆ°è¼¸å‡º>"
        step = classify_step(q)

        a, auto_used = pick_from_plan(step)

        # âœ… auto æ™‚ç”¨ä½ çš„ auto_answer ç”¢ç­”æ¡ˆï¼ˆè¦èƒ½æ”¶æ–‚ Step11ï¼‰
        if auto_used:
            if not allow_autofill:
                raise RuntimeError(f"[{name}] æ¸¬è©¦è¼¸å…¥ä¸å¤ ç”¨ / step-plan æœªè¦†è“‹ï¼šstep={step}")
            a = auto_answer(q)

        turns.append({
            "step": step,
            "auto": auto_used,
            "q": q,
            "a": a,
        })
        return a

    err = None
    out = ""
    try:
        with redirect_stdout(buf), patch("builtins.input", side_effect=scripted_input):
            if use_real_llm:
                with patch.object(agent.requests, "post", side_effect=wrapped_post):
                    agent.main()
            else:
                with patch.object(agent, "llm_extract", side_effect=fake_llm_extract):
                    agent.main()
    except Exception as e:
        err = e
    finally:
        out = buf.getvalue()

        auto_cnt = sum(1 for t in turns if t.get("auto"))
        log_name = f"{name}.txt" if err is None else f"FAIL_{name}.txt"
        log_path = os.path.join(log_dir, log_name)

        with open(log_path, "w", encoding="utf-8") as f:
            f.write(f"æ¸¬è©¦æ¡ˆä¾‹: {name}\n")
            f.write(f"use_real_llm: {use_real_llm}\n")
            f.write(f"llm_http_calls: {llm_calls['n']}\n")
            f.write(f"turns: {len(turns)}\n")
            f.write(f"auto_fills: {auto_cnt}\n")
            if err is not None:
                f.write(f"STATUS: FAIL\nERROR: {repr(err)}\n")
            else:
                f.write("STATUS: PASS\n")

            f.write("\n====================\n### Interleaved Transcript\n====================\n")
            for i, t in enumerate(turns, 1):
                f.write(f"\n--- Turn {i} ---\n")
                if t.get("auto"):
                    f.write("[AUTO-FILL]\n")
                f.write(f"[step={t.get('step')}]\n")
                f.write((t.get("q") or "").rstrip() + "\n")
                f.write("\nè¼¸å…¥:\n")
                f.write(str(t.get("a", "")) + "\n")

            f.write("\n====================\n### RAW STDOUT\n====================\n")
            f.write(out)

    if err is not None:
        raise err

    if use_real_llm and llm_calls["n"] == 0:
        raise AssertionError(f"[{name}] use_real_llm=True ä½† llm_http_calls=0ï¼Œä»£è¡¨æ²’æœ‰æ‰“åˆ° Ollamaã€‚")

    # æŠ“ FINAL_JSON
    final = None
    for line in reversed(out.splitlines()):
        if "FINAL_JSON:" in line:
            json_str = line.split("FINAL_JSON:", 1)[1].strip()
            final = json.loads(json_str)
            break

    if final is None:
        raise AssertionError(f"[{name}] æ‰¾ä¸åˆ° FINAL_JSONã€‚\n\nRAW:\n{out}")

    ok, reason = agent.validate_final_json(final)
    if not ok:
        raise AssertionError(f"[{name}] FINAL_JSON validator å¤±æ•—ï¼š{reason}\n\nRAW:\n{out}")

    log_path = os.path.join(log_dir, f"{name}.txt")
    auto_cnt = sum(1 for t in turns if t.get("auto"))

    print(
        f"âœ… [{name}] PASS | turns={len(turns)} | auto={auto_cnt} | "
        f"llm_http_calls={llm_calls['n']} | store_name={final.get('store_name')} | "
        f"capacity_hint={final.get('capacity_hint')} | log={log_path}"
    )
    return final, out, log_path

def main():
    # âœ… çœŸå¯¦ LLM å»ºè­°ç”¨ step-planï¼ˆä¾å•é¡Œå›è¦†ï¼‰
    TESTS: Dict[str, Dict[str, List[str]]] = {
        "happy_daily_open": {
            "store_name": ["123ç°¡é¤"],
            "resources": ["å››äººæ¡Œäº”å€‹ å…­äººæ¡Œå››å€‹ å…«äººæ¡Œä¸€å€‹"],
            "duration": ["A"],
            "hours": ["æ¯å¤© 08:00-17:00"],
            "hours_confirm": ["A"],
            "merge_tables": ["A"],
            "max_party_size": ["12äºº"],
            "online_role": ["A"],
            "peak_period": ["C"],
            "peak_ratio": ["C"],
            "peak_strategy": ["C"],
            "no_show": ["C"],
            "step11_confirm": ["A"],
        },

        "closed_sunday_no_merge": {
            "store_name": ["é€±æœ«å°é¤¨"],
            "resources": ["4äººæ¡Œ3å¼µ 6äººæ¡Œ2å¼µ"],
            "duration": ["B"],
            "hours": ["é€±ä¸€åˆ°é€±å…­ 08:00-17:00ï¼Œé€±æ—¥å…¬ä¼‘"],
            "hours_confirm": ["A"],
            "merge_tables": ["B"],  # ä¸å¯ä½µæ¡Œï¼ˆmax_party_size ä¸æœƒå•ï¼‰
            "online_role": ["B"],
            "peak_period": ["D"],
            "peak_ratio": ["B"],
            "peak_strategy": ["A"],
            "no_show": ["B"],
            "step11_confirm": ["A"],
        },

        "bad_resources_then_ok": {
            "store_name": ["æ¸¬è©¦åº—"],
            "resources": ["1+1", "4äººæ¡Œ2å¼µ 6äººæ¡Œ1å¼µ"],  # âœ… åŒ step é‡å•æœƒåƒä¸‹ä¸€å€‹
            "duration": ["A"],
            "hours": ["æ¯å¤© 08:00-17:00"],
            "hours_confirm": ["A"],
            "merge_tables": ["A"],
            "max_party_size": ["8äºº"],
            "online_role": ["B"],
            "peak_period": ["A"],
            "peak_ratio": ["B"],
            "peak_strategy": ["B"],
            "no_show": ["B"],
            "step11_confirm": ["A"],
        },

        "bad_duration_then_ok": {
            "store_name": ["äº‚ç­”åº—"],
            "resources": ["4äººæ¡Œ2å¼µ"],
            "duration": ["æˆ‘ä¸çŸ¥é“", "C"],  # âœ… é‡å•å¾Œæ”¹ç­”å°
            "hours": ["æ¯å¤© 08:00-17:00"],
            "hours_confirm": ["A"],
            "merge_tables": ["A"],
            "max_party_size": ["10"],
            "online_role": ["C"],
            "peak_period": ["E"],
            "peak_ratio": ["B"],
            "peak_strategy": ["A"],
            "no_show": ["C"],
            "step11_confirm": ["A"],
        },

        "bad_hours_then_ok": {
            "store_name": ["æ™‚é–“åº—"],
            "resources": ["4äººæ¡Œ2å¼µ 6äººæ¡Œ1å¼µ"],
            "duration": ["A"],
            "hours": ["è—è‰²å¥½å—ï¼Ÿ", "æ¯å¤© 08:00-17:00"],  # âœ… hours æŠ½ä¸åˆ°æœƒé‡å•
            "hours_confirm": ["A"],
            "merge_tables": ["A"],
            "max_party_size": ["12äºº"],
            "online_role": ["A"],
            "peak_period": ["C"],
            "peak_ratio": ["C"],
            "peak_strategy": ["B"],
            "no_show": ["B"],
            "step11_confirm": ["A"],
        },

        "hours_confirm_B_then_fix": {
            "store_name": ["æ”¹æ™‚é–“åº—"],
            "resources": ["4äººæ¡Œ2å¼µ"],
            "duration": ["B"],
            "hours": ["æ¯å¤© 08:00-17:00", "é€±ä¸€åˆ°é€±å…­ 09:00-18:00ï¼Œé€±æ—¥å…¬ä¼‘"],
            "hours_confirm": ["B", "A"],  # âœ… å…ˆèªªä¸å°ï¼Œå†ç¢ºèªæ­£ç¢º
            "merge_tables": ["A"],
            "max_party_size": ["8"],
            "online_role": ["B"],
            "peak_period": ["D"],
            "peak_ratio": ["A"],
            "peak_strategy": ["A"],
            "no_show": ["B"],
            "step11_confirm": ["A"],
        },

        "step11_modify_path": {
            "store_name": ["ä¿®æ”¹åº—"],
            "resources": ["4äººæ¡Œ3å¼µ 6äººæ¡Œ2å¼µ"],
            "duration": ["A"],
            "hours": ["æ¯å¤© 08:00-17:00"],
            "hours_confirm": ["A"],
            "merge_tables": ["A"],
            "max_party_size": ["12"],
            "online_role": ["A"],
            "peak_period": ["C"],
            "peak_ratio": ["B"],
            "peak_strategy": ["A"],
            "no_show": ["B"],
            # âœ… Step11ï¼šç¬¬ä¸€æ¬¡é¸ B é€²ä¿®æ”¹ï¼Œç¬¬äºŒæ¬¡é¸ A æ¥å—
            "step11_confirm": ["B", "A"],
            "step11_modify": ["å¿™æ™‚ 4 äººæ¡Œ 1 å¼µã€6 äººæ¡Œ 1 å¼µ"],
        },
    }

    for name, plan in TESTS.items():
        run_case(name, plan, use_real_llm=True, allow_autofill=True, max_turns=120)

    print("\nğŸ‰ All tests passed. Logs are under ./test_logs/")

if __name__ == "__main__":
    main()
